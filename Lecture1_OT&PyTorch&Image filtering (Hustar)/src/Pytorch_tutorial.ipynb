{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power of **Pytorch** 1 -  Similar to Numpy\n",
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_h = torch.randn(20, 20, requires_grad=True)\n",
    "W_x = torch.randn(20, 10, requires_grad=True)\n",
    "x = torch.randn(1,10)\n",
    "prev_h = torch.randn(1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(2.8769, grad_fn=&lt;SumBackward0&gt;)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "h2h = torch.matmul(W_h, prev_h.t())\n",
    "i2h = torch.matmul(W_x, x.t())\n",
    "\n",
    "next_h = h2h + i2h\n",
    "next_h = torch.tanh(next_h)\n",
    "\n",
    "loss = next_h.sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0.8864,  0.5315,  1.2139, -0.2338],\n        [-0.7460, -0.5691,  0.7210, -2.5029],\n        [-1.1092, -0.8486,  1.7451,  1.6269]])\ntensor([[-1.2343,  0.5202,  0.6143, -0.2477],\n        [-0.2830, -0.1058, -0.3630,  0.5957],\n        [-1.4092, -0.3625, -1.7572,  0.1520]])\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n"
    }
   ],
   "source": [
    "N, D = 3, 4\n",
    "\n",
    "x = torch.randn(N, D, requires_grad=True)\n",
    "y = torch.randn(N, D, requires_grad=True)\n",
    "z = torch.randn(N, D, requires_grad=True)\n",
    "\n",
    "a = x * y\n",
    "b = a + z\n",
    "c = torch.sum(b)\n",
    "\n",
    "c.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-5-a5f0f7ee003b&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 11\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         &quot;&quot;&quot;\n\u001b[0;32m--&gt; 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "N, D = 3, 4\n",
    "\n",
    "x = torch.randn(N, D, requires_grad=False)\n",
    "y = torch.randn(N, D, requires_grad=False)\n",
    "z = torch.randn(N, D, requires_grad=False)\n",
    "\n",
    "a = x * y\n",
    "b = a + z\n",
    "c = torch.sum(b)\n",
    "\n",
    "c.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.3755626"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "W_h_numpy = W_h.detach().numpy()\n",
    "prev_h_numpy = prev_h.numpy()\n",
    "\n",
    "## TO DO\n",
    "## First, copy the above code and change what...?\n",
    "h2h = np.matmul(W_h_numpy, prev_h_numpy.T)\n",
    "i2h = np.matmul(W_x.detach().numpy(), x.numpy().T)\n",
    "\n",
    "next_h = h2h + i2h\n",
    "next_h = np.tanh(next_h)\n",
    "\n",
    "loss = next_h.sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power of **Pytorch** 2 - Comparison of frameworks\n",
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n       [ 1.86755799, -0.97727788,  0.95008842, -0.15135721],\n       [-0.10321885,  0.4105985 ,  0.14404357,  1.45427351]])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.random.seed(0)\n",
    "\n",
    "N, D = 3, 4\n",
    "\n",
    "x = np.random.randn(N, D)\n",
    "y = np.random.randn(N, D)\n",
    "z = np.random.randn(N, D)\n",
    "\n",
    "a = x * y\n",
    "b = a + z\n",
    "c = np.sum(b)\n",
    "\n",
    "grad_c = 1.0\n",
    "## TO DO : Calculate manually gradients\n",
    "grad_b = grad_c * np.ones((N, D))\n",
    "grad_a = grad_b.copy()\n",
    "grad_z = grad_b.copy()\n",
    "grad_x = grad_a * y\n",
    "grad_y = grad_a * x\n",
    "grad_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/home/piai/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_quint8 = np.dtype([(&quot;quint8&quot;, np.uint8, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_qint16 = np.dtype([(&quot;qint16&quot;, np.int16, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_quint16 = np.dtype([(&quot;quint16&quot;, np.uint16, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_qint32 = np.dtype([(&quot;qint32&quot;, np.int32, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  np_resource = np.dtype([(&quot;resource&quot;, np.ubyte, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_quint8 = np.dtype([(&quot;quint8&quot;, np.uint8, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_qint16 = np.dtype([(&quot;qint16&quot;, np.int16, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_quint16 = np.dtype([(&quot;quint16&quot;, np.uint16, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  _np_qint32 = np.dtype([(&quot;qint32&quot;, np.int32, 1)])\n/home/piai/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.\n  np_resource = np.dtype([(&quot;resource&quot;, np.ubyte, 1)])\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "N, D = 3, 4\n",
    "\n",
    "x = tf.placeholder(tf.float64)\n",
    "y = tf.placeholder(tf.float64)\n",
    "z = tf.placeholder(tf.float64)\n",
    "\n",
    "a = x * y\n",
    "b = a + z\n",
    "c = tf.reduce_sum(b)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "## TO DO : use gradient function in Tensorflow \n",
    "grad_x, grad_y, grad_z = tf.gradients(c, [x, y, z])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    np.random.seed(0)\n",
    "    values = {\n",
    "        x: np.random.randn(N, D),\n",
    "        y: np.random.randn(N, D),\n",
    "        z: np.random.randn(N, D),\n",
    "  \n",
    "  }\n",
    "    # TO DO : run session\n",
    "    out = sess.run([c, grad_x, grad_y, grad_z], feed_dict=values)\n",
    "    c_v, grad_x_v, grad_y_v, grad_z_v = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "N, D = 3, 4\n",
    "\n",
    "x = torch.randn(N, D, requires_grad=True)\n",
    "y = torch.randn(N, D, requires_grad=True)\n",
    "z = torch.randn(N, D, requires_grad=True)\n",
    "\n",
    "a = x * y\n",
    "b = a + z\n",
    "c = torch.sum(b)\n",
    "\n",
    "c.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Tutorial\n",
    "- Indexing 과 broadcasting 복습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Array indexing\n",
    "* Numpy array의 indexing은 일반적인 list와 유사하다. \n",
    "* 단, indexing해서 분리한 array도 원래 array의 memory를 참조하기 때문에 변경할 때 유의하여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]] \n\n[[2 3]\n [6 7]]\n2\n77\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "print(a, '\\n')\n",
    "\n",
    "# [[2 3]\n",
    "#  [6 7]]\n",
    "# call-by-reference가 된 경우\n",
    "b = a[:2, 1:3]\n",
    "print(b)\n",
    "\n",
    "print(a[0, 1])\n",
    "b[0, 0] = 77    # b[0, 0] is the same piece of data as a[0, 1]\n",
    "print(a[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####  Slicing을 할 때는 dimension이 낮아질 수 있다.\n",
    "- Slicing을 하는 방법에는 여러가지가 있는데, integer를 활용해 indexing을 할 때는 dimension이 낮아지고, slicing을 이용해 indexing 할 때는 dimension이 유지된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]] (3, 4)\nSlicing Row\n[5 6 7 8] (4,)\n[[5 6 7 8]] (1, 4)\n[[5 6 7 8]] (1, 4)\nSlicing Column\n[ 2  6 10] (3,) \n\n[[ 2]\n [ 6]\n [10]] (3, 1)\n"
    }
   ],
   "source": [
    "# Create the following rank 2 array with shape (3, 4)\n",
    "a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "print(a, a.shape)\n",
    "\n",
    "row_r1 = a[1, :]    # Rank 1 view of the second row of a  \n",
    "row_r2 = a[1:2, :]  # Rank 2 view of the second row of a\n",
    "row_r3 = a[[1], :]  # Rank 2 view of the second row of a\n",
    "# row_r1 = np.expand_dims(row_r1, axis=0)\n",
    "print(\"Slicing Row\")\n",
    "print(row_r1, row_r1.shape)\n",
    "print(row_r2, row_r2.shape)\n",
    "print(row_r3, row_r3.shape)\n",
    "\n",
    "\n",
    "col_r1 = a[:, 1]\n",
    "col_r2 = a[:, 1:2]\n",
    "print(\"Slicing Column\")\n",
    "print(col_r1, col_r1.shape, '\\n')\n",
    "print(col_r2, col_r2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integer array를 이용해 indexing을 할 수 있다. \n",
    "- Slicing을 할 때는 네모난 subarray만 추출할 수 있지만, integer array를 이용할 경우 임의의 수치들을 꺼내올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1 4 5]\n[1 4 5]\n"
    }
   ],
   "source": [
    "a = np.array([[1,2], [3, 4], [5, 6]])\n",
    "\n",
    "print(np.array([a[0, 0], a[1, 1], a[2, 0]]))\n",
    "print(a[[0, 1, 2], [0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 1  2  3]\n [ 4  5  6]\n [ 7  8  9]\n [10 11 12]]\n[ 1  6  7 11]\n[[11  2  3]\n [ 4  5 16]\n [17  8  9]\n [10 21 12]]\n"
    }
   ],
   "source": [
    "# Create a new array from which we will select elements\n",
    "a = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
    "print(a)\n",
    "\n",
    "## TO DO \n",
    "# Select one element from each row of a using the indices\n",
    "b = np.array([0, 2, 0, 1])\n",
    "print(a[np.arange(4), b])  # Prints \"[ 1  6  7 11]\"\n",
    "\n",
    "a[np.arange(4), b] += 10\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean array로도 indexing을 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ True False  True]\n [ True  True  True]\n [ True  True  True]\n [ True  True  True]]\n[11  3  4  5 16 17  8  9 10 21 12]\n"
    }
   ],
   "source": [
    "print(a > 2)\n",
    "print(a[a > 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "- Broadcasting is strong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 2  2  4]\n [ 5  5  7]\n [ 8  8 10]\n [11 11 13]]\n[[ 2  2  4]\n [ 5  5  7]\n [ 8  8 10]\n [11 11 13]]\n[[ 2  2  4]\n [ 5  5  7]\n [ 8  8 10]\n [11 11 13]]\n"
    }
   ],
   "source": [
    "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
    "v = np.array([1, 0, 1])\n",
    "y = np.empty_like(x)   \n",
    "\n",
    "for i in range(4):\n",
    "    y[i, :] = x[i, :] + v\n",
    "print(y)\n",
    "\n",
    "vv = np.tile(v, (4, 1))  # Stack 4 copies of v on top of each other\n",
    "y = x + vv  \n",
    "print(y)\n",
    "\n",
    "y = x + v  # Add v to each row of x using broadcasting\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "wrong\ncorrect\ncorrect\nwrong\n"
    }
   ],
   "source": [
    "##Quiz\n",
    "def checkbroadcasting(x, y):\n",
    "    try:\n",
    "        x+y\n",
    "        print(\"correct\")\n",
    "    except:\n",
    "        print(\"wrong\")\n",
    "\n",
    "x=np.empty((0))\n",
    "y=np.empty((2,2))\n",
    "checkbroadcasting(x,y)\n",
    "        \n",
    "x=np.empty((5,3,4,1))\n",
    "y=np.empty((3,4,1))\n",
    "checkbroadcasting(x,y)\n",
    "\n",
    "x=np.empty((5,3,4,1))\n",
    "y=np.empty((3,1,1))\n",
    "checkbroadcasting(x,y)\n",
    "\n",
    "x=np.empty((5,2,4,1))\n",
    "y=np.empty((3,1,1))\n",
    "checkbroadcasting(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지금까지 배운 indexing 과 Broadcasting 방법이 ***모두*** Pytorch에도 적용 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "* Tensorflow의 Tensor와 다르지 않다.\n",
    "  * Numpy의 ndarrays를 기본적으로 활용하고 있다.\n",
    "  * Numpy의 ndarrays의 대부분의 operation을 사용할 수 있도록 구성되어 있다.\n",
    "* Numpy의 operation은 CPU만을 이용해 느리지만 Tensor는 CUDA를 활용해 GPU를 이용하기 때문에 빠르게 연산을 진행할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 1.2780e-42, 0.0000e+00],\n        [1.1210e-43, 0.0000e+00, 8.7673e-35],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [7.8473e-44, 2.8026e-45, 2.8026e-45]]) \n\ntensor([[0.2950, 0.5948, 0.1377],\n        [0.4909, 0.1862, 0.0055],\n        [0.2166, 0.2649, 0.0877],\n        [0.0480, 0.4886, 0.9765],\n        [0.4372, 0.1419, 0.2328]]) \n\ntensor([[3, 4, 5],\n        [1, 2, 3]]) \n\ntorch.Size([2, 3])\ntorch.Size([2, 3])\n"
    }
   ],
   "source": [
    "# Construct a 5 x 3 matrix, uninitialized\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x, '\\n')\n",
    "\n",
    "# Construct a randomly initialized matrix \n",
    "x = torch.rand(5, 3)\n",
    "print(x, '\\n')\n",
    "\n",
    "# Construct a matrix with the list\n",
    "x = torch.tensor([[3, 4, 5], [1, 2, 3]])\n",
    "print(x, '\\n')\n",
    "\n",
    "# Get its size\n",
    "print(x.size())\n",
    "print(x.shape) #???? is it Numpy? kkkkk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dtype and device \n",
    " * dtype - Tensor의 데이터 타입\n",
    " * device - Tensor의 작업 위치 (cpu or cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3., 4., 5.],\n        [1., 2., 3.]], dtype=torch.float64) \n\ntensor([[3, 4, 5],\n        [1, 2, 3]]) \n\ntensor([[ 6.,  8., 10.],\n        [ 2.,  4.,  6.]], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "x = torch.tensor([[3, 4, 5], [1, 2, 3]], dtype=torch.float64)\n",
    "print(x, '\\n')\n",
    "\n",
    "y = torch.tensor([[3, 4, 5], [1, 2, 3]])\n",
    "print(y, '\\n')\n",
    "\n",
    "#error\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3., 4., 5.],\n        [1., 2., 3.]], dtype=torch.float64) \n\ntensor([[ 6.,  8., 10.],\n        [ 2.,  4.,  6.]], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "y = y.double() \n",
    "print(y, '\\n')\n",
    "\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3., 4., 5.],\n        [1., 2., 3.]], device=&#39;cuda:1&#39;, dtype=torch.float64) \n\ncuda:1 \n\n"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "device = torch.device('cuda:1')\n",
    "x = x.to(device)\n",
    "\n",
    "print(x, '\\n')\n",
    "print(x.device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Before &quot;to&quot; method\ntorch.float64 cpu\ntorch.float32 cpu\ntorch.int32 cuda:1 \n\nAfter &quot;to&quot; method\ntorch.int32 cuda:0\ntorch.int32 cuda:1\ntorch.int32 cpu \n\n"
    }
   ],
   "source": [
    "device_0 = torch.device('cuda:0')\n",
    "device_1 = torch.device('cuda:1')\n",
    "\n",
    "x = torch.randn(4, 3, dtype=torch.float64)\n",
    "y = torch.randn(4, 3, dtype=torch.float32)\n",
    "z = torch.randint(0, 10, (4, 3), dtype=torch.int32)\n",
    "\n",
    "z = z.to(device_1)\n",
    "\n",
    "print('Before \"to\" method')\n",
    "\n",
    "print(x.dtype, x.device)\n",
    "print(y.dtype, y.device)\n",
    "print(z.dtype, z.device, '\\n')\n",
    "\n",
    "print('After \"to\" method')\n",
    "# to method with specific dtype and device \n",
    "x = x.to(dtype=torch.int32, device=device_0)\n",
    "\n",
    "# to method with some tensor \n",
    "y = y.to(z)\n",
    "z = z.to(device=\"cpu\")\n",
    "\n",
    "print(x.dtype, x.device)\n",
    "print(y.dtype, y.device)\n",
    "print(z.dtype, z.device, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing like Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 4.8654e+04,  4.5722e-41, -6.2216e-26,  0.0000e+00,  0.0000e+00],\n        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 2.6302e+20,  6.1949e-04,  1.0256e-08,  6.4456e-10,  3.1128e+12]]) \n\ntensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]]) \n\ntensor([[1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.]]) \n\ntensor([[3.1415, 3.1415, 3.1415, 3.1415, 3.1415],\n        [3.1415, 3.1415, 3.1415, 3.1415, 3.1415],\n        [3.1415, 3.1415, 3.1415, 3.1415, 3.1415]]) \n\ntensor([0, 2, 4]) \n\ntensor([0.0000, 0.6250, 1.2500, 1.8750, 2.5000, 3.1250, 3.7500, 4.3750, 5.0000]) \n\ntensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10]) \n\ntensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1.]]) \n\ntensor([[3, 7, 6, 4, 7],\n        [3, 6, 9, 5, 3],\n        [3, 3, 4, 7, 5]]) \n\n"
    }
   ],
   "source": [
    "x = torch.empty(3, 5)\n",
    "print(x, '\\n')\n",
    "\n",
    "x = torch.zeros(3, 5)\n",
    "print(x, '\\n')\n",
    "\n",
    "x = torch.ones(3, 5)\n",
    "print(x, '\\n')\n",
    "\n",
    "x = torch.full((3, 5), 3.1415)\n",
    "print(x, '\\n')\n",
    "\n",
    "x = torch.arange(0, 5, 2)\n",
    "print(x, '\\n')\n",
    "\n",
    "y = torch.linspace(0, 5, 9)\n",
    "print(y, '\\n')\n",
    "\n",
    "z = torch.logspace(-10, 10, 5)\n",
    "print(z, '\\n')\n",
    "\n",
    "z = torch.eye(5)\n",
    "print(z, '\\n')\n",
    "\n",
    "# Construct a 3 x 5 matrix with random value from uniform distribution, i.e. Uniform[0, 1)\n",
    "x = torch.rand(3, 5)\n",
    "\n",
    "# Construct a 3 x 5 matrix with random value from normal distribution, i.e. Normal(0, 1)\n",
    "x = torch.randn(3, 5)\n",
    "\n",
    "x = torch.randint(3, 10, (3, 5))\n",
    "print(x, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*\\_like function and new\\_\\* function\n",
    " * \\*\\_like: Tensor를 input으로 받아, Tensor 모양의 matrix를 return.\n",
    " * new\\_\\*: Shape를 input으로 받아, Tensor와 같은 type과 device를 가지는 matrix를 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]]) \n\ntensor([[0, 0, 0],\n        [0, 0, 0]]) \n\ntorch.int64 cpu\ntorch.int64 cpu \n\n"
    }
   ],
   "source": [
    "y = torch.zeros_like(x)\n",
    "print(y, '\\n')\n",
    "\n",
    "# Make zero matrix with attribute of x\n",
    "z = x.new_zeros(2, 3)\n",
    "print(z, '\\n')\n",
    "print(x.dtype, x.device)\n",
    "print(z.dtype, z.device,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n [1. 1. 1. 1. 1.] \n tensor([1., 1., 1., 1., 1.], dtype=torch.float64) \n [1. 1. 1. 1. 1.]\n"
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "c = b.numpy()\n",
    "print(\"\\n\",a,\"\\n\",b,\"\\n\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "* Operations에도 여러가지 syntax가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0.2840, 1.7311, 1.4480],\n        [1.1503, 0.3623, 1.0301],\n        [0.5567, 1.3016, 0.8032],\n        [1.0576, 1.6082, 0.5499],\n        [1.7389, 0.9164, 0.7721]]) \n\ntensor([[0.2840, 1.7311, 1.4480],\n        [1.1503, 0.3623, 1.0301],\n        [0.5567, 1.3016, 0.8032],\n        [1.0576, 1.6082, 0.5499],\n        [1.7389, 0.9164, 0.7721]]) \n\ntensor([[0.2840, 1.7311, 1.4480],\n        [1.1503, 0.3623, 1.0301],\n        [0.5567, 1.3016, 0.8032],\n        [1.0576, 1.6082, 0.5499],\n        [1.7389, 0.9164, 0.7721]]) \n\ntensor([[0.2840, 1.7311, 1.4480],\n        [1.1503, 0.3623, 1.0301],\n        [0.5567, 1.3016, 0.8032],\n        [1.0576, 1.6082, 0.5499],\n        [1.7389, 0.9164, 0.7721]]) \n\ntensor([0.8973, 0.3448, 0.6788, 0.9900, 0.5614]) \n\ntensor([0.8973, 0.5295, 0.6788, 0.9272, 0.9900, 0.9021, 0.5614])\n"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y, '\\n')\n",
    "\n",
    "print(torch.add(x, y), '\\n')\n",
    "\n",
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result, '\\n')\n",
    "\n",
    "y.add_(x)\n",
    "print(y, '\\n')\n",
    "\n",
    "# indexing 또한 비슷하게\n",
    "print(x[:, 1], '\\n')\n",
    "print(x[x > 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape -> view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) \n\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]]) \n\ntensor([[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11],\n        [12, 13, 14, 15, 16, 17],\n        [18, 19, 20, 21, 22, 23],\n        [24, 25, 26, 27, 28, 29]]) \n\ntorch.Size([5, 6]) \n\ntensor([[[ 0,  1,  2,  3,  4],\n         [ 5,  6,  7,  8,  9]],\n\n        [[10, 11, 12, 13, 14],\n         [15, 16, 17, 18, 19]],\n\n        [[20, 21, 22, 23, 24],\n         [25, 26, 27, 28, 29]]]) \n\ntorch.Size([3, 2, 5]) \n\n"
    }
   ],
   "source": [
    "# Change the shape of tensor \n",
    "x = torch.arange(0, 10)\n",
    "print(x, '\\n')\n",
    "\n",
    "y = x.view(2, 5)\n",
    "print(y, '\\n')\n",
    "\n",
    "x = torch.arange(0, 30).view(5, 6)\n",
    "print(x, '\\n')\n",
    "print(x.size(), '\\n')\n",
    "\n",
    "y = x.view(-1, 2, 5)\n",
    "print(y, '\\n')\n",
    "print(y.size(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand_dim -> unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]]) \n\ntensor([[0, 5],\n        [1, 6],\n        [2, 7],\n        [3, 8],\n        [4, 9]]) torch.Size([5, 2]) \n\ntorch.Size([1, 2, 5]) \n\ntorch.Size([2, 1, 5]) \n\ntorch.Size([2, 5]) \n\n"
    }
   ],
   "source": [
    "# Change the dimension of tensor\n",
    "x = torch.arange(0, 10).view(2, 5)\n",
    "print(x, '\\n')\n",
    "\n",
    "# view를 사용하기 까다로울때 사용\n",
    "y = x.permute(1, 0)\n",
    "print(y, y.shape, '\\n')\n",
    "\n",
    "# Add the dimension of tensor \n",
    "z = x.unsqueeze(0)\n",
    "print(z.size(), '\\n')\n",
    "\n",
    "z = x.unsqueeze(1)\n",
    "print(z.size(), '\\n')\n",
    "\n",
    "# size=1 인 dimension 제거\n",
    "z = z.squeeze()\n",
    "print(z.size(), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiplication and concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 3]) torch.Size([5, 3])\ntensor([[6., 6., 6.],\n        [6., 6., 6.],\n        [6., 6., 6.],\n        [6., 6., 6.],\n        [6., 6., 6.]]) torch.Size([5, 3])\ntensor([[18., 18., 18., 18., 18.],\n        [18., 18., 18., 18., 18.],\n        [18., 18., 18., 18., 18.],\n        [18., 18., 18., 18., 18.],\n        [18., 18., 18., 18., 18.]]) torch.Size([5, 5])\ntorch.Size([2, 5, 3])\n"
    }
   ],
   "source": [
    "x = torch.ones( 5, 3)+1\n",
    "y = torch.ones( 5, 3)+2\n",
    "z = x * y\n",
    "print(x.shape, y.shape)\n",
    "print(z, z.shape)\n",
    "\n",
    "z= torch.matmul(x, y.t())\n",
    "print(z, z.shape)\n",
    "\n",
    "x = x.unsqueeze(0)\n",
    "y = y.unsqueeze(0)\n",
    "z = torch.cat([x, y], dim=0)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tile -> expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([100, 700, 28])\ntorch.Size([100, 28, 700])\n"
    }
   ],
   "source": [
    "x = torch.randn(100, 700)\n",
    "x = x.unsqueeze(2).expand(100, 700, 28)\n",
    "print(x.shape)\n",
    "\n",
    "x = torch.randn(100, 700)\n",
    "x = x.unsqueeze(1).expand(100, 28, 700)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\***********Numpy Practice Time\\***********\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = torch.ones(4,5,4,4)\n",
    "ch_insert= torch.ones(4,2,4,4)*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]]],\n\n\n        [[[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]]],\n\n\n        [[[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]]],\n\n\n        [[[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]],\n\n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]]]])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "src_uns2 = src.unsqueeze(2)\n",
    "ch_insert_uns1 = ch_insert.unsqueeze(1)\n",
    "expand_dim = list(src_uns2.shape)\n",
    "expand_dim[2] = ch_insert_uns1.shape[2]\n",
    "ch_insert_uns1 = ch_insert_uns1.expand(tuple(expand_dim))\n",
    "cated_tensor = torch.cat([ch_insert_uns1, src_uns2], dim=2)\n",
    "result = cated_tensor.view(expand_dim[0],expand_dim[1]*(expand_dim[2]+1),expand_dim[3],expand_dim[4])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: automatic differentiation\n",
    "* Autograd package는 Tensors가 사용할 수 있는 모든 Operation의 Gradient를 자동으로 계산해준다.\n",
    "* Tensor의 required_grad attribute를 이용해 gradient의 계산여부를 결정할 수 있다.\n",
    "  * 계산이 완료된 이후에 .backward()를 호출하면 자동으로 gradient를 계산한다.\n",
    "  * .grad attribute를 통해 마찬가지로 gradient에 접근할 수 있다. \n",
    "  * .grad_fn attribute를 통해 해당 Variable이 어떻게 생성되었는지 확인할 수 있다.\n",
    "  \n",
    "  \n",
    "![Alt text](./resource/Variable.png \"Variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1.],\n        [1., 1.]], requires_grad=True)\nTrue\n"
    }
   ],
   "source": [
    "# Create a variable\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3., 3.],\n        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)\nNone\n&lt;AddBackward0 object at 0x7f73be78e6a0&gt;\ntensor([[27., 27.],\n        [27., 27.]], grad_fn=&lt;MulBackward0&gt;) &lt;MulBackward0 object at 0x7f73540965c0&gt; \n\ntensor(27., grad_fn=&lt;MeanBackward0&gt;)\n"
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n",
    "\n",
    "# y는 operation으로 생성된 결과이기 때문에 grad_fn이 있지만 , x는 없다.\n",
    "print(x.grad_fn)\n",
    "print(y.grad_fn)\n",
    "\n",
    "# Do more operations on y \n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, z.grad_fn, '\\n')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradients \n",
    "* out.backward()을 하면 out의 gradient를 1로 시작해 Back-propagation을 시작한다.\n",
    "* .backward()를 호출한 이후부터는 .grad를 통해 각 변수의 gradient를 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[4.5000, 4.5000],\n        [4.5000, 4.5000]])\n"
    }
   ],
   "source": [
    "# out.backward() == out.backward(tr.Tensor([1.0]))\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 실제로 Gradient 를 계산하면 다음과 같다.\n",
    "$$o = \\frac{1}{4}\\sum_{i} z_{i}$$ \n",
    "\n",
    "$$z_{i}=3(x_{i}+2)^{2}$$\n",
    "\n",
    "$$z_{i}|_{x_{i}=1} = 27 $$\n",
    "\n",
    "$$ \\frac{\\partial o}{\\partial x_{i}} = \\frac{3}{2}(x_{i} + 2) $$\n",
    "\n",
    "$$ \\frac{\\partial o}{\\partial x_{i}}|_{x_{i}=1} = 4.5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 534.7814, -698.1065, -950.7838], grad_fn=&lt;MulBackward0&gt;)\ntensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
    }
   ],
   "source": [
    "# We can do many crazy thing with autograd\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "# y = 1024 * x\n",
    "print(y)\n",
    "\n",
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
    "y.backward(gradients)\n",
    "# 1024\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "## 1. Define the network\n",
    "* nn.Module 을 inherit하는 class를 define한다.\n",
    "  * __init__(self): 생성자, network에서 사용할 구조를 정의한다.\n",
    "  * forward(self, x): x를 input으로 받는 network가 어떻게 작동해 어떤 output을 내놓을지 정의한다.\n",
    "  * backward(self, grad_output): grad_output을 받아 직전 layer로 gradient를 backpropagation해주는 함수. 기본적으로는 autograd를 통해 자동으로 정의된다.\n",
    "  \n",
    "  ![convnet](./resource/mnist.png \"Variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Net(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적으로 네트워크의 파라미터가 많으면 많을수록 성능이 좋다. 하지만 상황에 따라 다르다\n",
    "# 예를 들어 모바일의 경우 파라미터가 적은것이 오히려 유리하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10\ntorch.Size([6, 1, 5, 5])\n61706\ntensor([[-0.0319,  0.0164,  0.0172, -0.0917, -0.1121,  0.0737,  0.0797, -0.0112,\n          0.1140, -0.0198]], grad_fn=&lt;AddmmBackward&gt;)\n"
    }
   ],
   "source": [
    "# The learnable parameters of a model are returned by net.parameters()\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())\n",
    "print(sum(p.numel() for p in params))# 파라미터 수를 계산하는 코드\n",
    "\n",
    "# The input to the forward is a tensor, and so is the output\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "* Loss function은 (output, target) 을 input으로 받아 그 차이를 return한다.\n",
    "* 직접 구현할 수도 있지만 대부분의 일반적인 loss는 대부분 nn package에 구현되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(38.3322, grad_fn=&lt;MseLossBackward&gt;)\n&lt;MseLossBackward object at 0x7fdd0ab55f98&gt;\n&lt;AddmmBackward object at 0x7fdd0ab55ef0&gt;\n&lt;ReluBackward0 object at 0x7fdd0ab55e10&gt;\n"
    }
   ],
   "source": [
    "# For example\n",
    "output = net(input)\n",
    "target = torch.arange(1, 11).unsqueeze(0)  # a dummy target, for example\n",
    "criterion = nn.MSELoss()# Loss정의는 대부분의 경우 그냥 가져오면 된다.\n",
    "\n",
    "# 만약 커스텀 로스를 구현하려면? L1 Loss\n",
    "# Torch.abs(output - target)\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "# You can follow loss in the backward direction, using it's .grad_fn attribute\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[1][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop\n",
    "* Back-propagation을 위해서는 여러번 언급했듯이 loss.backward()를 이용한다.\n",
    "* net.zero_grad()를 이용해 먼저 모든 parameter의 gradient buffer에 0을 대입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Found dtype Long but expected Float\nException raised from compute_types at /pytorch/aten/src/ATen/native/TensorIterator.cpp:183 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fdd7858c1e2 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: at::TensorIterator::compute_types(at::TensorIteratorConfig const&amp;) + 0x259 (0x7fdd5ccc1849 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: at::TensorIterator::build(at::TensorIteratorConfig&amp;) + 0x6b (0x7fdd5ccc4feb in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&amp;) + 0xdd (0x7fdd5ccc565d in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: at::native::mse_loss_backward_out(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x18a (0x7fdd5cb2a2ba in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::native::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x90 (0x7fdd5cb26ce0 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #6: &lt;unknown function&gt; + 0x10fa2f9 (0x7fdd5cf392f9 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: &lt;unknown function&gt; + 0xa9ac76 (0x7fdd5c8d9c76 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: at::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x119 (0x7fdd5cfe9949 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: &lt;unknown function&gt; + 0x2e03469 (0x7fdd5ec42469 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: &lt;unknown function&gt; + 0xa9ac76 (0x7fdd5c8d9c76 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: at::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x119 (0x7fdd5cfe9949 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: torch::autograd::generated::MseLossBackward::apply(std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt;&amp;&amp;) + 0x1af (0x7fdd5eb7e0cf in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: &lt;unknown function&gt; + 0x3375bb7 (0x7fdd5f1b4bb7 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::evaluate_function(std::shared_ptr&lt;torch::autograd::GraphTask&gt;&amp;, torch::autograd::Node*, torch::autograd::InputBuffer&amp;, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt; const&amp;) + 0x1400 (0x7fdd5f1b0400 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::Engine::thread_main(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;) + 0x451 (0x7fdd5f1b0fa1 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: torch::autograd::Engine::execute_with_graph_task(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, std::shared_ptr&lt;torch::autograd::Node&gt;) + 0x37c (0x7fdd5f1ae6bc in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: torch::autograd::python::PythonEngine::execute_with_graph_task(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, std::shared_ptr&lt;torch::autograd::Node&gt;) + 0x3c (0x7fdd7933e8dc in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #18: torch::autograd::Engine::execute(std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; const&amp;, bool, bool, std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;) + 0x803 (0x7fdd5f1ad9f3 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::python::PythonEngine::execute(std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; const&amp;, bool, bool, std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;) + 0x4e (0x7fdd7933e6de in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #20: THPEngine_run_backward(THPEngine*, _object*, _object*) + 0xa54 (0x7fdd7933f3c4 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #21: /usr/bin/python3() [0x50a7f5]\nframe #22: _PyEval_EvalFrameDefault + 0x1226 (0x50cfd6 in /usr/bin/python3)\nframe #23: /usr/bin/python3() [0x507f24]\nframe #24: /usr/bin/python3() [0x509c50]\nframe #25: /usr/bin/python3() [0x50a64d]\nframe #26: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #27: /usr/bin/python3() [0x507f24]\nframe #28: /usr/bin/python3() [0x509c50]\nframe #29: /usr/bin/python3() [0x50a64d]\nframe #30: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #31: /usr/bin/python3() [0x507f24]\nframe #32: /usr/bin/python3() [0x5165a5]\nframe #33: /usr/bin/python3() [0x50a47f]\nframe #34: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #35: /usr/bin/python3() [0x58e3ea]\nframe #36: _PyEval_EvalFrameDefault + 0x19dc (0x50d78c in /usr/bin/python3)\nframe #37: /usr/bin/python3() [0x58e3ea]\nframe #38: _PyEval_EvalFrameDefault + 0x19dc (0x50d78c in /usr/bin/python3)\nframe #39: /usr/bin/python3() [0x58e3ea]\nframe #40: /usr/bin/python3() [0x50a51c]\nframe #41: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #42: /usr/bin/python3() [0x509918]\nframe #43: /usr/bin/python3() [0x50a64d]\nframe #44: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #45: /usr/bin/python3() [0x509918]\nframe #46: /usr/bin/python3() [0x50a64d]\nframe #47: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #48: /usr/bin/python3() [0x507f24]\nframe #49: _PyFunction_FastCallDict + 0x2e2 (0x509202 in /usr/bin/python3)\nframe #50: /usr/bin/python3() [0x594b01]\nframe #51: PyObject_Call + 0x3e (0x59fe1e in /usr/bin/python3)\nframe #52: _PyEval_EvalFrameDefault + 0x17e6 (0x50d596 in /usr/bin/python3)\nframe #53: /usr/bin/python3() [0x507f24]\nframe #54: /usr/bin/python3() [0x509c50]\nframe #55: /usr/bin/python3() [0x50a64d]\nframe #56: _PyEval_EvalFrameDefault + 0x1226 (0x50cfd6 in /usr/bin/python3)\nframe #57: /usr/bin/python3() [0x58e809]\nframe #58: /usr/bin/python3() [0x513def]\nframe #59: /usr/bin/python3() [0x50a47f]\nframe #60: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #61: /usr/bin/python3() [0x507f24]\nframe #62: /usr/bin/python3() [0x509c50]\nframe #63: /usr/bin/python3() [0x50a64d]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-11-bd0e6b5797a0&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(net.conv1.bias.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 6\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(&#39;conv1.bias.grad after backward&#39;)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         &quot;&quot;&quot;\n\u001b[0;32m--&gt; 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float\nException raised from compute_types at /pytorch/aten/src/ATen/native/TensorIterator.cpp:183 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fdd7858c1e2 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: at::TensorIterator::compute_types(at::TensorIteratorConfig const&amp;) + 0x259 (0x7fdd5ccc1849 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: at::TensorIterator::build(at::TensorIteratorConfig&amp;) + 0x6b (0x7fdd5ccc4feb in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&amp;) + 0xdd (0x7fdd5ccc565d in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: at::native::mse_loss_backward_out(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x18a (0x7fdd5cb2a2ba in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::native::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x90 (0x7fdd5cb26ce0 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #6: &lt;unknown function&gt; + 0x10fa2f9 (0x7fdd5cf392f9 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: &lt;unknown function&gt; + 0xa9ac76 (0x7fdd5c8d9c76 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: at::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x119 (0x7fdd5cfe9949 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: &lt;unknown function&gt; + 0x2e03469 (0x7fdd5ec42469 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: &lt;unknown function&gt; + 0xa9ac76 (0x7fdd5c8d9c76 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: at::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x119 (0x7fdd5cfe9949 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: torch::autograd::generated::MseLossBackward::apply(std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt;&amp;&amp;) + 0x1af (0x7fdd5eb7e0cf in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: &lt;unknown function&gt; + 0x3375bb7 (0x7fdd5f1b4bb7 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::evaluate_function(std::shared_ptr&lt;torch::autograd::GraphTask&gt;&amp;, torch::autograd::Node*, torch::autograd::InputBuffer&amp;, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt; const&amp;) + 0x1400 (0x7fdd5f1b0400 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::Engine::thread_main(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;) + 0x451 (0x7fdd5f1b0fa1 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: torch::autograd::Engine::execute_with_graph_task(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, std::shared_ptr&lt;torch::autograd::Node&gt;) + 0x37c (0x7fdd5f1ae6bc in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: torch::autograd::python::PythonEngine::execute_with_graph_task(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, std::shared_ptr&lt;torch::autograd::Node&gt;) + 0x3c (0x7fdd7933e8dc in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #18: torch::autograd::Engine::execute(std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; const&amp;, bool, bool, std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;) + 0x803 (0x7fdd5f1ad9f3 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::python::PythonEngine::execute(std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; const&amp;, bool, bool, std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;) + 0x4e (0x7fdd7933e6de in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #20: THPEngine_run_backward(THPEngine*, _object*, _object*) + 0xa54 (0x7fdd7933f3c4 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #21: /usr/bin/python3() [0x50a7f5]\nframe #22: _PyEval_EvalFrameDefault + 0x1226 (0x50cfd6 in /usr/bin/python3)\nframe #23: /usr/bin/python3() [0x507f24]\nframe #24: /usr/bin/python3() [0x509c50]\nframe #25: /usr/bin/python3() [0x50a64d]\nframe #26: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #27: /usr/bin/python3() [0x507f24]\nframe #28: /usr/bin/python3() [0x509c50]\nframe #29: /usr/bin/python3() [0x50a64d]\nframe #30: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #31: /usr/bin/python3() [0x507f24]\nframe #32: /usr/bin/python3() [0x5165a5]\nframe #33: /usr/bin/python3() [0x50a47f]\nframe #34: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #35: /usr/bin/python3() [0x58e3ea]\nframe #36: _PyEval_EvalFrameDefault + 0x19dc (0x50d78c in /usr/bin/python3)\nframe #37: /usr/bin/python3() [0x58e3ea]\nframe #38: _PyEval_EvalFrameDefault + 0x19dc (0x50d78c in /usr/bin/python3)\nframe #39: /usr/bin/python3() [0x58e3ea]\nframe #40: /usr/bin/python3() [0x50a51c]\nframe #41: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #42: /usr/bin/python3() [0x509918]\nframe #43: /usr/bin/python3() [0x50a64d]\nframe #44: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #45: /usr/bin/python3() [0x509918]\nframe #46: /usr/bin/python3() [0x50a64d]\nframe #47: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #48: /usr/bin/python3() [0x507f24]\nframe #49: _PyFunction_FastCallDict + 0x2e2 (0x509202 in /usr/bin/python3)\nframe #50: /usr/bin/python3() [0x594b01]\nframe #51: PyObject_Call + 0x3e (0x59fe1e in /usr/bin/python3)\nframe #52: _PyEval_EvalFrameDefault + 0x17e6 (0x50d596 in /usr/bin/python3)\nframe #53: /usr/bin/python3() [0x507f24]\nframe #54: /usr/bin/python3() [0x509c50]\nframe #55: /usr/bin/python3() [0x50a64d]\nframe #56: _PyEval_EvalFrameDefault + 0x1226 (0x50cfd6 in /usr/bin/python3)\nframe #57: /usr/bin/python3() [0x58e809]\nframe #58: /usr/bin/python3() [0x513def]\nframe #59: /usr/bin/python3() [0x50a47f]\nframe #60: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #61: /usr/bin/python3() [0x507f24]\nframe #62: /usr/bin/python3() [0x509c50]\nframe #63: /usr/bin/python3() [0x50a64d]\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "# print('conv1.bias.grad before backward')\n",
    "# print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# print('conv1.bias.grad after backward')\n",
    "# print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;net&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-6-6f506a24e5b2&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name &#39;net&#39; is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Found dtype Long but expected Float\nException raised from compute_types at /pytorch/aten/src/ATen/native/TensorIterator.cpp:183 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fdd7858c1e2 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: at::TensorIterator::compute_types(at::TensorIteratorConfig const&amp;) + 0x259 (0x7fdd5ccc1849 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: at::TensorIterator::build(at::TensorIteratorConfig&amp;) + 0x6b (0x7fdd5ccc4feb in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&amp;) + 0xdd (0x7fdd5ccc565d in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: at::native::mse_loss_backward_out(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x18a (0x7fdd5cb2a2ba in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::native::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x90 (0x7fdd5cb26ce0 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #6: &lt;unknown function&gt; + 0x10fa2f9 (0x7fdd5cf392f9 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: &lt;unknown function&gt; + 0xa9ac76 (0x7fdd5c8d9c76 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: at::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x119 (0x7fdd5cfe9949 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: &lt;unknown function&gt; + 0x2e03469 (0x7fdd5ec42469 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: &lt;unknown function&gt; + 0xa9ac76 (0x7fdd5c8d9c76 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: at::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x119 (0x7fdd5cfe9949 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: torch::autograd::generated::MseLossBackward::apply(std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt;&amp;&amp;) + 0x1af (0x7fdd5eb7e0cf in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: &lt;unknown function&gt; + 0x3375bb7 (0x7fdd5f1b4bb7 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::evaluate_function(std::shared_ptr&lt;torch::autograd::GraphTask&gt;&amp;, torch::autograd::Node*, torch::autograd::InputBuffer&amp;, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt; const&amp;) + 0x1400 (0x7fdd5f1b0400 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::Engine::thread_main(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;) + 0x451 (0x7fdd5f1b0fa1 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: torch::autograd::Engine::execute_with_graph_task(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, std::shared_ptr&lt;torch::autograd::Node&gt;) + 0x37c (0x7fdd5f1ae6bc in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: torch::autograd::python::PythonEngine::execute_with_graph_task(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, std::shared_ptr&lt;torch::autograd::Node&gt;) + 0x3c (0x7fdd7933e8dc in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #18: torch::autograd::Engine::execute(std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; const&amp;, bool, bool, std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;) + 0x803 (0x7fdd5f1ad9f3 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::python::PythonEngine::execute(std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; const&amp;, bool, bool, std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;) + 0x4e (0x7fdd7933e6de in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #20: THPEngine_run_backward(THPEngine*, _object*, _object*) + 0xa54 (0x7fdd7933f3c4 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #21: /usr/bin/python3() [0x50a7f5]\nframe #22: _PyEval_EvalFrameDefault + 0x1226 (0x50cfd6 in /usr/bin/python3)\nframe #23: /usr/bin/python3() [0x507f24]\nframe #24: /usr/bin/python3() [0x509c50]\nframe #25: /usr/bin/python3() [0x50a64d]\nframe #26: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #27: /usr/bin/python3() [0x507f24]\nframe #28: /usr/bin/python3() [0x509c50]\nframe #29: /usr/bin/python3() [0x50a64d]\nframe #30: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #31: /usr/bin/python3() [0x507f24]\nframe #32: /usr/bin/python3() [0x5165a5]\nframe #33: /usr/bin/python3() [0x50a47f]\nframe #34: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #35: /usr/bin/python3() [0x58e3ea]\nframe #36: _PyEval_EvalFrameDefault + 0x19dc (0x50d78c in /usr/bin/python3)\nframe #37: /usr/bin/python3() [0x58e3ea]\nframe #38: _PyEval_EvalFrameDefault + 0x19dc (0x50d78c in /usr/bin/python3)\nframe #39: /usr/bin/python3() [0x58e3ea]\nframe #40: /usr/bin/python3() [0x50a51c]\nframe #41: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #42: /usr/bin/python3() [0x509918]\nframe #43: /usr/bin/python3() [0x50a64d]\nframe #44: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #45: /usr/bin/python3() [0x509918]\nframe #46: /usr/bin/python3() [0x50a64d]\nframe #47: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #48: /usr/bin/python3() [0x507f24]\nframe #49: _PyFunction_FastCallDict + 0x2e2 (0x509202 in /usr/bin/python3)\nframe #50: /usr/bin/python3() [0x594b01]\nframe #51: PyObject_Call + 0x3e (0x59fe1e in /usr/bin/python3)\nframe #52: _PyEval_EvalFrameDefault + 0x17e6 (0x50d596 in /usr/bin/python3)\nframe #53: /usr/bin/python3() [0x507f24]\nframe #54: /usr/bin/python3() [0x509c50]\nframe #55: /usr/bin/python3() [0x50a64d]\nframe #56: _PyEval_EvalFrameDefault + 0x1226 (0x50cfd6 in /usr/bin/python3)\nframe #57: /usr/bin/python3() [0x58e809]\nframe #58: /usr/bin/python3() [0x513def]\nframe #59: /usr/bin/python3() [0x50a47f]\nframe #60: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #61: /usr/bin/python3() [0x507f24]\nframe #62: /usr/bin/python3() [0x509c50]\nframe #63: /usr/bin/python3() [0x50a64d]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-12-e50108964c92&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 12\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Does the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         &quot;&quot;&quot;\n\u001b[0;32m--&gt; 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float\nException raised from compute_types at /pytorch/aten/src/ATen/native/TensorIterator.cpp:183 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fdd7858c1e2 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: at::TensorIterator::compute_types(at::TensorIteratorConfig const&amp;) + 0x259 (0x7fdd5ccc1849 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: at::TensorIterator::build(at::TensorIteratorConfig&amp;) + 0x6b (0x7fdd5ccc4feb in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&amp;) + 0xdd (0x7fdd5ccc565d in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: at::native::mse_loss_backward_out(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x18a (0x7fdd5cb2a2ba in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::native::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x90 (0x7fdd5cb26ce0 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #6: &lt;unknown function&gt; + 0x10fa2f9 (0x7fdd5cf392f9 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: &lt;unknown function&gt; + 0xa9ac76 (0x7fdd5c8d9c76 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: at::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x119 (0x7fdd5cfe9949 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: &lt;unknown function&gt; + 0x2e03469 (0x7fdd5ec42469 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: &lt;unknown function&gt; + 0xa9ac76 (0x7fdd5c8d9c76 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: at::mse_loss_backward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long) + 0x119 (0x7fdd5cfe9949 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: torch::autograd::generated::MseLossBackward::apply(std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt;&amp;&amp;) + 0x1af (0x7fdd5eb7e0cf in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: &lt;unknown function&gt; + 0x3375bb7 (0x7fdd5f1b4bb7 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::evaluate_function(std::shared_ptr&lt;torch::autograd::GraphTask&gt;&amp;, torch::autograd::Node*, torch::autograd::InputBuffer&amp;, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt; const&amp;) + 0x1400 (0x7fdd5f1b0400 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::Engine::thread_main(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;) + 0x451 (0x7fdd5f1b0fa1 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: torch::autograd::Engine::execute_with_graph_task(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, std::shared_ptr&lt;torch::autograd::Node&gt;) + 0x37c (0x7fdd5f1ae6bc in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: torch::autograd::python::PythonEngine::execute_with_graph_task(std::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, std::shared_ptr&lt;torch::autograd::Node&gt;) + 0x3c (0x7fdd7933e8dc in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #18: torch::autograd::Engine::execute(std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; const&amp;, bool, bool, std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;) + 0x803 (0x7fdd5f1ad9f3 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::python::PythonEngine::execute(std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; const&amp;, bool, bool, std::vector&lt;torch::autograd::Edge, std::allocator&lt;torch::autograd::Edge&gt; &gt; const&amp;) + 0x4e (0x7fdd7933e6de in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #20: THPEngine_run_backward(THPEngine*, _object*, _object*) + 0xa54 (0x7fdd7933f3c4 in /home/piai/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #21: /usr/bin/python3() [0x50a7f5]\nframe #22: _PyEval_EvalFrameDefault + 0x1226 (0x50cfd6 in /usr/bin/python3)\nframe #23: /usr/bin/python3() [0x507f24]\nframe #24: /usr/bin/python3() [0x509c50]\nframe #25: /usr/bin/python3() [0x50a64d]\nframe #26: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #27: /usr/bin/python3() [0x507f24]\nframe #28: /usr/bin/python3() [0x509c50]\nframe #29: /usr/bin/python3() [0x50a64d]\nframe #30: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #31: /usr/bin/python3() [0x507f24]\nframe #32: /usr/bin/python3() [0x5165a5]\nframe #33: /usr/bin/python3() [0x50a47f]\nframe #34: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #35: /usr/bin/python3() [0x58e3ea]\nframe #36: _PyEval_EvalFrameDefault + 0x19dc (0x50d78c in /usr/bin/python3)\nframe #37: /usr/bin/python3() [0x58e3ea]\nframe #38: _PyEval_EvalFrameDefault + 0x19dc (0x50d78c in /usr/bin/python3)\nframe #39: /usr/bin/python3() [0x58e3ea]\nframe #40: /usr/bin/python3() [0x50a51c]\nframe #41: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #42: /usr/bin/python3() [0x509918]\nframe #43: /usr/bin/python3() [0x50a64d]\nframe #44: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #45: /usr/bin/python3() [0x509918]\nframe #46: /usr/bin/python3() [0x50a64d]\nframe #47: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #48: /usr/bin/python3() [0x507f24]\nframe #49: _PyFunction_FastCallDict + 0x2e2 (0x509202 in /usr/bin/python3)\nframe #50: /usr/bin/python3() [0x594b01]\nframe #51: PyObject_Call + 0x3e (0x59fe1e in /usr/bin/python3)\nframe #52: _PyEval_EvalFrameDefault + 0x17e6 (0x50d596 in /usr/bin/python3)\nframe #53: /usr/bin/python3() [0x507f24]\nframe #54: /usr/bin/python3() [0x509c50]\nframe #55: /usr/bin/python3() [0x50a64d]\nframe #56: _PyEval_EvalFrameDefault + 0x1226 (0x50cfd6 in /usr/bin/python3)\nframe #57: /usr/bin/python3() [0x58e809]\nframe #58: /usr/bin/python3() [0x513def]\nframe #59: /usr/bin/python3() [0x50a47f]\nframe #60: _PyEval_EvalFrameDefault + 0x444 (0x50c1f4 in /usr/bin/python3)\nframe #61: /usr/bin/python3() [0x507f24]\nframe #62: /usr/bin/python3() [0x509c50]\nframe #63: /usr/bin/python3() [0x50a64d]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time \n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "tensor([[ 0.0141,  0.1376,  0.0434,  0.1120, -0.0666,  0.0737,  0.0570,\n",
      "          0.0077,  0.1031,  0.1704]], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "net.to(device)\n",
    "input = torch.randn(1, 1, 32, 32, device=device)\n",
    "\n",
    "out = net(input)\n",
    "\n",
    "print(out, out.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and DataLoader\n",
    "* Tensorflow와 가장 크게 다른 점. \n",
    "* Tensorflow에서는 dataset과 loader의 form이 구체적이지 않았으나, PyTorch에서는 dataset과 DataLoader의 구체적인 form을 제공하고 쉽게 Batch를 만들 수 있도록 한다.\n",
    "  * torch.utils.data.Dataset: Neural Network에 사용하고자 하는 dataset에서 이미지를 뽑아주는 역할을 하는 class. 여기서 image의  pre-processing을 할 수 있다.\n",
    "  * torch.utils.data.DataLoader: Dataset을 통해 전처리된 이미지를 batch_size 개수만큼 뽑아 batch를 만들어주는 역할을 하는 class. 이미지의 순서를 섞는 등의 효과를 사용할 수도 있다.\n",
    "  * 직접 구현하는 것도 가능하지만 다음 시간에 활용하고자 한다.\n",
    "* 유명한 dataset의 경우 pytorch (torchvision.datasets)에서 기본적으로 제공한다. \n",
    "  * MNIST \n",
    "  * COCO (Captions, Detection)\n",
    "  * LSUN\n",
    "  * ImageFolder\n",
    "  * Imagenet-12\n",
    "  * CIFAR\n",
    "  * STL10\n",
    "  * SVHN\n",
    "  * PhotoTour\n",
    "  \n",
    "### Transform\n",
    "* Data augmentation을 위한 변환을 자동으로 수행해주는 함수\n",
    "* torchvision.transforms에 위치하고 있음\n",
    "  * 역시 직접 구현도 가능하다. 이도 역시 다음 시간에 활용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Transform\n",
    "# Data를 읽으면 numpy → tensor == transform.ToTensor()\n",
    "# Data값 범위 0~255 → -1 ~ 1 == transform.Normalize()\n",
    "# 노말라이즈 값은 데이터의 평균과 편차를 넣어주는것이 가장 좋다.\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8,\n",
    "                                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4     0     2     2     6     4     3     4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABPCAYAAAD7qT6JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIIQJohCFwRBCBP+H+jHj1X/sO9rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4b984e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j].item() for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}